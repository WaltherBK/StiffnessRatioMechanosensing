{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1663f0e1",
   "metadata": {},
   "source": [
    "# Generate Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bc86160",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pyefd import elliptic_fourier_descriptors\n",
    "import pyefd\n",
    "import cv2 as cv\n",
    "from scipy.spatial import ConvexHull, convex_hull_plot_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79c0efa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPORT_AXIAL = '/Users/asears/work/confocal/axial_features/'\n",
    "EXPORT_CROSS = '/Users/asears/work/confocal/lateral_features/'\n",
    "BASE_DIR = 'export_contours/' # For loading contours\n",
    "\n",
    "lines = ['parent', 'hgps', 'rs', 'huvec']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547dfff5",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22d021c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combines the up and down portions of a cell cross section\n",
    "def combine_halves(c, n, midpoint=18, reduce=True):\n",
    "    a = c[:,n,:]\n",
    "    b = np.array(list(reversed(c[:,n-18, :])))\n",
    "    res = np.vstack([a,b])\n",
    "    if reduce:\n",
    "        res = res[:,[0,2]]\n",
    "    return res\n",
    "\n",
    "\n",
    "# Loads points from a contour file\n",
    "def fetch_pts(fname, dims=2):\n",
    "    pts = open(fname,'r').readlines()\n",
    "    pts = [_.strip().split(',') for _ in pts[5:]]\n",
    "    return np.array([_[2:2+dims] for _ in pts],dtype=float)\n",
    "\n",
    "\n",
    "# Calculates efc ratio\n",
    "def efc_ratio(contour, order, doPlot, return_axes=True):\n",
    "    coeffs = elliptic_fourier_descriptors(contour, order=order)\n",
    "    semiaxes = np.array([np.sqrt(coeffs[:,0]**2+coeffs[:,2]**2), np.sqrt(coeffs[:,1]**2+coeffs[:,3]**2)])\n",
    "    efcr = 2*semiaxes[0][0]+2*semiaxes[1][0]+2\n",
    "    efcr /= 2*np.sum(semiaxes[:,1:])\n",
    "    \n",
    "    if doPlot:\n",
    "        dc = pyefd.calculate_dc_coefficients(contour)\n",
    "        print(contour[0]-dc)\n",
    "\n",
    "        recd = pyefd.reconstruct_contour(coeffs, locus=(0, 0), num_points=300)\n",
    "        plt.plot(recd.T[0], recd.T[1])\n",
    "        plt.scatter(contour.T[0]-dc[0], contour.T[1]-dc[1], color='k')\n",
    "        plt.show()\n",
    "        \n",
    "#     print(np.array(semiaxes))\n",
    "    if return_axes:\n",
    "        return efcr, semiaxes\n",
    "    else:\n",
    "        return efcr\n",
    "#     pass\n",
    "\n",
    "\n",
    "# Gets convex hull for a contour\n",
    "def get_hull(c):\n",
    "    hull = ConvexHull(c)\n",
    "    hullpts = c[hull.vertices]\n",
    "#     print('perimeter:', hull.area, hull.volume)\n",
    "\n",
    "    return hull, hullpts\n",
    "\n",
    "\n",
    "# calculates perimeter for a 2D contour\n",
    "def get_perimeter(c):\n",
    "    p = 0\n",
    "    for a,b in zip(c,c[1:]):\n",
    "        p+= np.sqrt((b[0]-a[0])**2+(b[1]-a[1])**2)\n",
    "        \n",
    "    p += np.sqrt((c[0][0]-c[-1][0])**2+(c[0][1]-c[-1][1])**2) # closure\n",
    "    return p\n",
    "        \n",
    "\n",
    "# Gets area for a contour in 2D\n",
    "def polyArea2D(pts):\n",
    "    lines = np.hstack([pts,np.roll(pts,-1,axis=0)])\n",
    "    area = 0.5*abs(sum(x1*y2-x2*y1 for x1,y1,x2,y2 in lines))\n",
    "    return area\n",
    "\n",
    "\n",
    "# calculates solidity, convexity, circularity, efcr in 2D\n",
    "def get_metrics(c, order=15):\n",
    "    _, hull = get_hull(c)\n",
    "    \n",
    "    area = polyArea2D(c)\n",
    "    area_convex = polyArea2D(hull)\n",
    "    \n",
    "    perim = get_perimeter(c)\n",
    "    perim_convex = get_perimeter(hull)\n",
    "    \n",
    "    solidity = area / area_convex\n",
    "    convexity = perim_convex / perim\n",
    "    formfactor = 3.14159*4*area/perim**2 # aka circularity\n",
    "    \n",
    "    efcr = efc_ratio(c, order=order, doPlot=False, return_axes=False)\n",
    "    \n",
    "    return solidity, convexity, formfactor, efcr\n",
    "\n",
    "def get_first_efcr(path, lines, n=3, targetn=4):\n",
    "    line_data = [np.load(os.path.join(path, f'{line}.npy')) for line in lines]\n",
    "#     print('summ shape:', line_data[0].shape)\n",
    "\n",
    "    with open(os.path.join(path, f'summary_{targetn}.txt'),'w') as fout:\n",
    "        for k,line in enumerate(lines):\n",
    "#             print('line_data[k].shape', line_data[k].shape) # 7, 10, 4\n",
    "            temp = line_data[k][:,0,:] # take the first contour's metrics, instead of a mean over levels\n",
    "#             print('temp.shape', temp.shape)\n",
    "            fout.write(f'{line}\\t'+'\\t'.join([str(round(t,4)) for t in temp[:,n]])+'\\n')\n",
    "        # print(','.join([str(np.mean(line_data[_],1)[n],4) for _ in range(len(line_data))]))\n",
    "\n",
    "def summarize_metrics(path, lines, n=0):\n",
    "    line_data = [np.load(os.path.join(path, f'{line}.npy')) for line in lines]\n",
    "#     print('summ shape:', line_data[0].shape)\n",
    "\n",
    "    with open(os.path.join(path, f'summary_{n}.txt'),'w') as fout:\n",
    "        for k,line in enumerate(lines):\n",
    "            temp = np.mean(line_data[k],1)\n",
    "#             print('temp.shape', temp.shape)\n",
    "            fout.write(f'{line}\\t'+'\\t'.join([str(round(t,4)) for t in temp[:,n]])+'\\n')\n",
    "        # print(','.join([str(np.mean(line_data[_],1)[n],4) for _ in range(len(line_data))]))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac1b931",
   "metadata": {},
   "source": [
    "## Axial Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1141e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "7 ../export_contours/lateral_parent_P00_1/C_Nuc_Z01.txt\n",
      "../export_contours/lateral_parent_P00_1/ (10, 4)\n",
      "../export_contours/lateral_parent_P00_2/ (10, 4)\n",
      "../export_contours/lateral_parent_P00_3/ (10, 4)\n",
      "../export_contours/lateral_parent_P00_4/ (10, 4)\n",
      "../export_contours/lateral_parent_P00_5/ (10, 4)\n",
      "../export_contours/lateral_parent_P00_6/ (10, 4)\n",
      "../export_contours/lateral_parent_P00_7/ (10, 4)\n",
      "10\n",
      "7 ../export_contours/lateral_hgps_P00_1/C_Nuc_Z01.txt\n",
      "../export_contours/lateral_hgps_P00_1/ (10, 4)\n",
      "../export_contours/lateral_hgps_P00_2/ (10, 4)\n",
      "../export_contours/lateral_hgps_P00_4/ (10, 4)\n",
      "../export_contours/lateral_hgps_P00_5/ (10, 4)\n",
      "../export_contours/lateral_hgps_P00_6/ (10, 4)\n",
      "../export_contours/lateral_hgps_P00_7/ (10, 4)\n",
      "../export_contours/lateral_hgps_P00_8/ (10, 4)\n",
      "10\n",
      "5 ../export_contours/lateral_rs_P00_2/C_Nuc_Z01.txt\n",
      "../export_contours/lateral_rs_P00_2/ (10, 4)\n",
      "../export_contours/lateral_rs_P00_3/ (10, 4)\n",
      "../export_contours/lateral_rs_P00_5/ (10, 4)\n",
      "../export_contours/lateral_rs_P00_6/ (10, 4)\n",
      "../export_contours/lateral_rs_P00_7/ (10, 4)\n",
      "10\n",
      "7 ../export_contours/lateral_huvec_P00_1/C_Nuc_Z01.txt\n",
      "../export_contours/lateral_huvec_P00_1/ (10, 4)\n",
      "../export_contours/lateral_huvec_P00_2/ (10, 4)\n",
      "../export_contours/lateral_huvec_P00_3/ (10, 4)\n",
      "../export_contours/lateral_huvec_P00_4/ (10, 4)\n",
      "../export_contours/lateral_huvec_P00_5/ (10, 4)\n",
      "../export_contours/lateral_huvec_P00_6/ (10, 4)\n",
      "../export_contours/lateral_huvec_P00_7/ (10, 4)\n"
     ]
    }
   ],
   "source": [
    "# Load contours\n",
    "# calculate features for each contour, axially\n",
    "\n",
    "os.makedirs(EXPORT_AXIAL,exist_ok=True)\n",
    "\n",
    "with open(os.path.join(EXPORT_AXIAL,'axial_summary.txt'),'w') as fout:\n",
    "    fout.write('# Axial features' + '\\n')\n",
    "\n",
    "\n",
    "for line in lines:\n",
    "    dirs = list(sorted(glob.glob(f'../export_contours/lateral_{line}_P00_*/')))\n",
    "    files = list(sorted(glob.glob(os.path.join(dirs[0],'C_N*Z*.txt')))); print(len(files))\n",
    "    print(len(dirs),files[0])\n",
    "    \n",
    "    all_line = []\n",
    "    for celldir in dirs:\n",
    "#         print(celldir)\n",
    "        cellfiles = list(sorted(glob.glob(os.path.join(celldir,'C_N*Z*.txt'))));\n",
    "        \n",
    "        contours_nuc = np.array([fetch_pts(f, dims=2) for f in cellfiles])\n",
    "        m = np.array([get_metrics(c) for c in contours_nuc])\n",
    "        all_line.append(m)\n",
    "        print(celldir, np.shape(m))\n",
    "        \n",
    "    with open(os.path.join(EXPORT_AXIAL,'axial_summary.txt'),'a') as fout:\n",
    "#             to_write = [round(_,4) for _ in [np.mean(all_line[:,:,0]),np.mean(all_line[:,:,1]),np.mean(all_line[:,:,2])]]\n",
    "#             print(line, to_write)\n",
    "\n",
    "        fout.write('# ' + line + '\\n')\n",
    "\n",
    "        meaned_cell = np.mean(all_line,1)\n",
    "#         print('meaned_cell_shape', meaned_cell.shape)\n",
    "\n",
    "        for cell in meaned_cell:\n",
    "            fout.write(','.join([str(round(_,4)) for _ in cell]) + '\\n')\n",
    "        fout.write('\\n\\n')\n",
    "\n",
    "        np.save(os.path.join(EXPORT_AXIAL,f'{line}.npy'),all_line)\n",
    "\n",
    "            # print(np.mean(meaned_cell,0), np.std(meaned_cell,0))\n",
    "            # fout.write(','.join([str(round(_,4)) for _ in np.mean(meaned_cell,0)]))\n",
    "#         all_line = np.array(all_line)\n",
    "#         print(line, all_line.shape)\n",
    "#         np.save(os.path.join(EXPORT_AXIAL,f'{line}.npy'), all_line)\n",
    "\n",
    "\n",
    "\n",
    "summarize_metrics(EXPORT_AXIAL, lines, 0)\n",
    "summarize_metrics(EXPORT_AXIAL, lines, 1)\n",
    "summarize_metrics(EXPORT_AXIAL, lines, 2)\n",
    "summarize_metrics(EXPORT_AXIAL, lines, 3)\n",
    "get_first_efcr(EXPORT_AXIAL, lines, 3, targetn=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74034db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9042aa3",
   "metadata": {},
   "source": [
    "## Lateral Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bce667",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for line in lines:\n",
    "    dirs = list(sorted(glob.glob(os.path.join(BASE_DIR, f'lateral_{line}_P00_*/'))))\n",
    "    files = list(sorted(glob.glob(os.path.join(dirs[0],'C_N*Z*.txt')))); print(len(files))\n",
    "    print(len(dirs),files[0])\n",
    "\n",
    "    all_line = []\n",
    "    for celldir in dirs:\n",
    "#         print(celldir)\n",
    "        cellfiles = list(sorted(glob.glob(os.path.join(celldir,'C_N*Z*.txt'))));\n",
    "\n",
    "        contours_nuc = np.array([fetch_pts(f, dims=3) for f in cellfiles])\n",
    "\n",
    "        all_cell = []\n",
    "        for n in range(contours_nuc.shape[1]):\n",
    "            combined = combine_halves(contours_nuc,n) \n",
    "            latmetrics = get_metrics(combined)\n",
    "            all_cell.append(latmetrics)\n",
    "#             print(celldir, latmetrics)\n",
    "        all_line.append(all_cell)\n",
    "    all_line = np.array(all_line)\n",
    "    print(np.shape(all_line))\n",
    "    for cell, celldir in zip(range(len(all_line)), dirs):\n",
    "        with open(os.path.join(EXPORT_CROSS,f'{line}_cell_{cell}.txt'),'w') as fout:\n",
    "            fout.write('# '+celldir + '\\n')\n",
    "            for theta in all_line[cell]:\n",
    "                fout.write(','.join([str(round(_,4)) for _ in theta]) + '\\n')\n",
    "\n",
    "\n",
    "    with open(os.path.join(EXPORT_CROSS,f'xsection_summary.txt'),'a') as fout:\n",
    "        to_write = [round(_,4) for _ in [np.mean(all_line[:,:,0]),np.mean(all_line[:,:,1]),np.mean(all_line[:,:,2])]]\n",
    "        print(line, to_write)\n",
    "\n",
    "        fout.write('# ' + line + '\\n')\n",
    "\n",
    "        meaned_cell = np.mean(all_line,1)\n",
    "        print(meaned_cell.shape)\n",
    "\n",
    "        for cell in meaned_cell:\n",
    "            fout.write(','.join([str(round(_,4)) for _ in cell]) + '\\n')\n",
    "        fout.write('\\n\\n')\n",
    "\n",
    "    np.save(os.path.join(EXPORT_CROSS,f'{line}.npy'),all_line)\n",
    "\n",
    "        # print(np.mean(meaned_cell,0), np.std(meaned_cell,0))\n",
    "        # fout.write(','.join([str(round(_,4)) for _ in np.mean(meaned_cell,0)]))\n",
    "\n",
    "summarize_metrics(EXPORT_CROSS, lines, 0)\n",
    "summarize_metrics(EXPORT_CROSS, lines, 1)\n",
    "summarize_metrics(EXPORT_CROSS, lines, 2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
